{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai-les8-02-fully-connected.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqIGe1NuCvrF",
        "colab_type": "code",
        "outputId": "c85726ad-fcce-4981-b669-afa708bf05b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 29.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 36.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 34.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 42.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 36.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=223b8ed1d137cd271fe037b63f9577e58e0f590f11e00e016505f5e8399080a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pITGcpwiNV_I",
        "colab_type": "code",
        "outputId": "0a1fa084-98c9-4802-f308-7b878f2f881a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/les8'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLmRUoS7N_Y_",
        "colab_type": "code",
        "outputId": "0a837ef6-d8b2-4000-fed7-92e95fa9aefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/fastai-v3/les8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/fastai-v3/les8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wmwwl4mOKs-",
        "colab_type": "code",
        "outputId": "e85c2458-a2b3-49b5-8b1a-f91506e813cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/fastai-v3/les8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3vUvNzjORlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feQVKOVYOguO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_01 import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP7__rMqOnYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "  path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "  with gzip.open(path, 'rb') as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "  return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14QKeakPkyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMz-rPy_PyWl",
        "colab_type": "code",
        "outputId": "cffa1e3a-f837-44c5-874f-63aaac5886da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# calculate the mean and standard deviation\n",
        "train_mean,train_std = x_train.mean(), x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-mswk8Ak1Vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the values\n",
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "# NB: Use training, not validation mean for validation set\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn00kYd0lLDG",
        "colab_type": "code",
        "outputId": "b4123a33-a352-4d3d-8ad9-3b3eea7fb145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check the updated values\n",
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRq2PKll3Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kmHLx7NmVjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIgL_ioxr_D3",
        "colab_type": "text"
      },
      "source": [
        "Take a look at the training data\n",
        "\n",
        "Note the size of the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDdKS48_mhpz",
        "colab_type": "code",
        "outputId": "1c93a918-e8e8-4110-ac63-3b6296d2d3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_rjHJC4mrLO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Foundations version\n",
        "\n",
        "Basic architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvKqHlv6mtYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num hidden layer\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhgBeCimzPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simplified kaiming init / the init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5CbTGacnYXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJatfwXUnsDs",
        "colab_type": "code",
        "outputId": "d4a07420-8feb-4e6e-9435-c77ffbfd7164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_valid.mean(),x_valid.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbZUNMvhvmQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x, w, b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPDxOoQpvsM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmXUDfm-vwuq",
        "colab_type": "code",
        "outputId": "92da71a3-0ef9-4ef4-b547-2482d211169c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#...so should this, because we used kaiming init, which is designed to do this\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0882), tensor(0.9954))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDnWUpFAv94k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FZ-jQ1wDHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cidSbGyMwHmg",
        "colab_type": "code",
        "outputId": "ed704001-bba9-4516-cbf2-a8356f896631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#...actually it really should be this!\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3531), tensor(0.5548))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djfLQ4FdwYt7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "From pytorch docs: a: the negative slope of the rectifier used after this layer (0 for ReLU by default)\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "This was introduced in the paper that described the Imagenet-winning approach from He et al: Delving Deep into Rectifiers, which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUbf6LtqwZ1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQOB2CkdwsFS",
        "colab_type": "code",
        "outputId": "55223784-6210-41af-e8e5-7e4b433c7959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(7.7074e-05), tensor(0.0503))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7gUJ_MIw3B6",
        "colab_type": "code",
        "outputId": "1957c922-e7be-4b89-c6f0-8f135d33cdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6457), tensor(0.9058))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xF-4dSYw_Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vjk45iWPsCQ",
        "colab_type": "text"
      },
      "source": [
        "fan_out vs. fan_in means that either you divide by the square root of m or the square root of nh And what is the difference? When we use m it will give the variance of 1 during forward pass but when we use nh the variance will be 1 during backward pass. fan_out is same as using nh so why are we using it and how it can be the same as using m ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFQ-RbgqxEvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns7k2pKfyFkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.kaiming_normal_??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUkCjpjjyORX",
        "colab_type": "code",
        "outputId": "37e58963-d430-40aa-e8d0-5f467956c2c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0004), tensor(0.0503))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXQmRU1ayTPz",
        "colab_type": "code",
        "outputId": "e670e17a-379d-4080-8c63-45d320cab026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6060), tensor(0.8697))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6efwaPTyXN_",
        "colab_type": "code",
        "outputId": "c521edbc-634f-4cfa-d596-3b9dd94e3936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRzQK9FyZzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQgTRKwrycpb",
        "colab_type": "code",
        "outputId": "cfb3506d-c30f-4257-9dd0-5eca50622f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlEHr3sEyjsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT1bUbAjysbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7dcXftPyym5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igVkpg63y3y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP99DFTty_JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#what if...?\n",
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ3WvX51zI1g",
        "colab_type": "code",
        "outputId": "63e83e3d-b481-4464-e6f3-a2fd99d45883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#kaiming init / the init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m)\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0864), tensor(0.8840))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IawHZogE8Tzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "  l1 = lin(xb, w1, b1)\n",
        "  l2 = relu(l1)\n",
        "  l3 = lin(l2, w2, b2)\n",
        "  return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDma7TNw8gtx",
        "colab_type": "code",
        "outputId": "f8770a2e-e006-4eae-b185-dd31fdb56a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%timeit -n 10 _=model(x_valid) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 20.5 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYiV4m7k9crX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVQO74T1-zQq",
        "colab_type": "text"
      },
      "source": [
        "Loss function: MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qNPrDKW-1wg",
        "colab_type": "code",
        "outputId": "64565ff0-1d39-49c0-89cc-34e400199016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAULPHhi-55q",
        "colab_type": "text"
      },
      "source": [
        "We need squeeze() to get rid of that trailing (,1), in order to use mse. (Of course, mse is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use mse for now to keep things simple.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABexFc7B-73r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export \n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar5MPZ39AVk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXZEJOXUAc0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GOzslf_AgTr",
        "colab_type": "code",
        "outputId": "dcd0c535-8665-4acd-ad66-947e007c8111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPazzk_yAkIq",
        "colab_type": "code",
        "outputId": "ea9ea549-d5ec-4539-abaa-6c615815185a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28.1745)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciKIyw3AHagr",
        "colab_type": "text"
      },
      "source": [
        "Gradients and backward pass \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdAYc1cXHbUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ):\n",
        "  # grad of loss with respect to output of previous layer\n",
        "  inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtT5KqcHv7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "  # grad of relu with respect to input activations\n",
        "  inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P15u_ILSH5kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "  # grad of matmul with respect to input\n",
        "  inp.g = out.g @ w.t()\n",
        "  w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "  b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3a5f3iwIRXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "  # forward pass:\n",
        "  l1 = inp @ w1 + b1\n",
        "  l2 = relu(l1)\n",
        "  out = l2 @ w2 + b2\n",
        "  # we don't actually need the loss in backward!\n",
        "  loss = mse(out, targ)\n",
        "  \n",
        "  #backward pass:\n",
        "  mse_grad(out, targ)\n",
        "  lin_grad(l2, out, w2, b2)\n",
        "  relu_grad(l1, l2)\n",
        "  lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuDzb2TyI82_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMSaNhxoJBIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save for testing against later\n",
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4KCllS5JUJv",
        "colab_type": "text"
      },
      "source": [
        "We cheat a little bit and use PyTorch autograd to check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rn7aD8nJVEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NyRU3cMJsrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "  # forward pass:\n",
        "  l1 = inp @ w12 + b12\n",
        "  l2 = relu(l1)\n",
        "  out = l2 @ w22 + b22\n",
        "  # we don't actually need the loss in backward!\n",
        "  return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7O3fhn5LUDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBzurUKgLYIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvwqOOrHLaQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w22.grad, w2g)\n",
        "test_near(b22.grad, b2g)\n",
        "test_near(w12.grad, w1g)\n",
        "test_near(b12.grad, b1g)\n",
        "test_near(xt2.grad, ig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHjyOnDALupp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Refactor model\n",
        "Layers as classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYvQYSkLtfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)-0.5\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOdBRPcAYpgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        # Creating a giant outer product, just to sum it, is inefficient!\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNqhi5M1Zg9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcTqv0WBaGwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6PjgpGBa4Mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtk9ZvvJcYTy",
        "colab_type": "code",
        "outputId": "b6ca3604-4a22-4474-86af-9e16f5335544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 120 ms, sys: 989 µs, total: 121 ms\n",
            "Wall time: 121 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqufElQccfuG",
        "colab_type": "code",
        "outputId": "8004db65-c269-4362-9e88-9a204ba50f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.58 s, sys: 4.76 s, total: 8.34 s\n",
            "Wall time: 8.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRcga3_zcmZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaZw_N30c36G",
        "colab_type": "text"
      },
      "source": [
        "Module.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t24HDZmc6DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "  def __call__(self, *args):\n",
        "    self.args = args\n",
        "    self.out = self.forward(*args)\n",
        "    return self.out\n",
        "  \n",
        "  def forward(self): raise Exception('not implemented')\n",
        "  def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOPUapRdU-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "  def forward(self, inp): return inp.clamp_min(0.) - 0.5\n",
        "  def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL0Cb51fdsyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eYRsyFteOht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvMxfghetPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkAhtc06ezZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxgN7t3efayp",
        "colab_type": "code",
        "outputId": "5b194e52-6d1d-4311-a7ff-92087c6127a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 120 ms, sys: 116 µs, total: 120 ms\n",
            "Wall time: 121 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXYylNvGgH4l",
        "colab_type": "code",
        "outputId": "e6094015-50f1-46f6-bd8f-6a853f71f6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 239 ms, sys: 26.8 ms, total: 266 ms\n",
            "Wall time: 279 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAMCmxq7gMJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-UFAaDXgbGX",
        "colab_type": "text"
      },
      "source": [
        "Without einsum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxX45e3ygd1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "  def __init__(self, w, b): self.w,self.b = w,b\n",
        "    \n",
        "  def forward(self, inp): return inp@self.w + self.b\n",
        "  \n",
        "  def bwd(self, out, inp):\n",
        "    inp.g = out.g @ self.w.t()\n",
        "    self.w.g = inp.t() @ out.g\n",
        "    self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvfeTfmWg8N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHVelqGUhDxO",
        "colab_type": "code",
        "outputId": "69c81b08-12f2-4c70-e499-6aea0c7cef19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 121 ms, sys: 172 µs, total: 121 ms\n",
            "Wall time: 122 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyEllBHGhSjK",
        "colab_type": "code",
        "outputId": "f6547a6d-1682-4664-cfa6-136d606a4ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 244 ms, sys: 1.91 ms, total: 246 ms\n",
            "Wall time: 248 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O80wNSvShONp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vgnEbpVhg_5",
        "colab_type": "text"
      },
      "source": [
        "nn.Linear and nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOyk4EHxhkgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNLRNYNLoQaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih3Tw72CoTKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyfcFXeVoaBS",
        "colab_type": "code",
        "outputId": "5c1d37bb-2d0f-48de-a88e-257e7a21e717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 106 ms, sys: 1.18 ms, total: 107 ms\n",
            "Wall time: 113 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4nKLXc8ogQE",
        "colab_type": "code",
        "outputId": "b4f5487d-cdd3-45fd-b921-b090d224c2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 80.2 ms, sys: 506 µs, total: 80.8 ms\n",
            "Wall time: 80.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iAqyC72pZPc",
        "colab_type": "code",
        "outputId": "fff38daa-4d3e-4b56-9db8-686fc117aab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/fastai-v3/les8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1wr8L_UolpW",
        "colab_type": "text"
      },
      "source": [
        "Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrAS6qndokvE",
        "colab_type": "code",
        "outputId": "920632b8-9f58-446d-8674-e44bf26e608b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!python notebook2script.py 02_fully_connected.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 02_fully_connected.ipynb to exp/nb_02.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}