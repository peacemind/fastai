{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai-les9-03-minibatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LihW_1ajfuyU",
        "colab_type": "code",
        "outputId": "dc6dcc15-933a-41d3-a467-c6320ebcfd2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ojMgDwUf2qb",
        "colab_type": "code",
        "outputId": "4d477287-76d5-4b4a-d44b-62c59d3582a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My\\ Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/les8'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEC-1hQjgYc9",
        "colab_type": "code",
        "outputId": "26b7afaf-4155-4baf-a978-b001a57575c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/fastai-v3/les8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/fastai-v3/les8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NAUQs54gs6E",
        "colab_type": "code",
        "outputId": "208ccc77-c3e7-46d2-8514-b26230f12491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/fastai-v3/les8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-t-Gyd2gxWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pGVqCFTg8DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyoGNskohULq",
        "colab_type": "text"
      },
      "source": [
        "Initial setup\n",
        "\n",
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeXIvCPWhSdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF-dbjQchcyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSVafCIDhit_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5nCEhnPo0-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzUcB1uipW_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7LGqX5ApaRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgMBFBXlpghd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Cross entropy loss\n",
        "\n",
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "\n",
        "or more concisely:\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
        "\n",
        "In practice, we will need the log of the softmax when we calculate the loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jsEgi3opjC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7-4pKZeqCMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AblIXzyqHzW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uI5hJqHqK9p",
        "colab_type": "code",
        "outputId": "9c07cd36-725f-4c46-9d5a-c01c4f128cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4lj2xZTqZOm",
        "colab_type": "code",
        "outputId": "d3ede14d-e580-42dd-eece-1aae96bf5442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "sm_pred[[0,1,2], [5,0,4]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.3870, -2.2695, -2.2568], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzyxy_fgqg4X",
        "colab_type": "code",
        "outputId": "0c486820-79c6-407f-9f07-7272b28e9fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj5liz5PqmH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P7rfzFUq3MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keOyJmGJq7QM",
        "colab_type": "code",
        "outputId": "f5a6cb28-0f03-481e-c32f-3542eae796c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3003, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHs2hRlq-rk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Note that the formula\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEC9fKMQrA_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNxsfogWsPdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bZb5649sYbk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrKHs16NsZZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAB6w_CP5-vK",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHdaXp3Y59d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbWa1aNK6MQa",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our log_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfPZv-yl6OOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq1v-XMp6bR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkR5W7N06iOi",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxBAvG16kjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdtqTMUf7Hp4",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnSAdqgy7FLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYWoaqW77SKR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Basic training loop\n",
        "\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "    get the output of the model on a batch of inputs\n",
        "    compare the output to the labels we have and compute a loss\n",
        "    calculate the gradients of the loss with respect to every parameter of the model\n",
        "    update said parameters with those gradients to make them a little bit better\n",
        "\n",
        "Jump_to lesson 9 video\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_CCRJnG7Up1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-rYr9qRBbZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def accuracy(out, yb): return(torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E8pF6RwBqcV",
        "colab_type": "code",
        "outputId": "7b6a1ca3-4a9d-4cb7-b89e-045daee866e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bs=64                          # batch size\n",
        "\n",
        "xb = x_train[0:bs]             # a mini-batch from x\n",
        "preds = model(xb)              # predictions\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0287,  0.0665, -0.0467, -0.0731, -0.0531, -0.0991,  0.0717, -0.0700,\n",
              "         -0.0159,  0.0271], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNs-2CnAB__t",
        "colab_type": "code",
        "outputId": "b4584136-de95-4482-82eb-4f40ad9d8a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2926, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hfd3KP_CFlf",
        "colab_type": "code",
        "outputId": "6805ae08-f9be-44e7-bf04-0499bea65ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgVmLPo1FANR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5        # learning rate\n",
        "epochs = 1      # how many epochs to train for"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgilgf6cFL7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        loss = loss_func(model(xb), yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for l in model.layers:\n",
        "                if hasattr(l, 'weight'):\n",
        "                    l.weight -= l.weight.grad * lr\n",
        "                    l.bias   -= l.bias.grad   * lr\n",
        "                    l.weight.grad.zero_()\n",
        "                    l.bias  .grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IIJO-RnGGCs",
        "colab_type": "code",
        "outputId": "cfd9dd36-a93d-4980-b6e4-6b1c43c117e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1286, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKJtPOzGrYr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Using parameters and optim\n",
        "Parameters\n",
        "\n",
        "Use nn.Module.__setattr__ and move relu to functional:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYOrj2dzGsJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in,nh)\n",
        "    self.l2 = nn.Linear(nh,n_out)\n",
        "    \n",
        "  def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ealQTgCLIA40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGlnkJcAIFEU",
        "colab_type": "code",
        "outputId": "ab386e09-d960-48de-fa88-ac0cf69d87e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMFsvy8AInZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mWF9WglIq8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "      start_i = i*bs\n",
        "      end_i = start_i+bs\n",
        "      xb = x_train[start_i:end_i]\n",
        "      yb = y_train[start_i:end_i]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      \n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters(): p -= p.grad * lr\n",
        "        model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nnH-W4QJUZF",
        "colab_type": "code",
        "outputId": "6e68eeb6-3c9d-44be-f8b0-7309ea8eb020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0750, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB3QMPNXJeid",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldyo5UWXJghx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in,nh)\n",
        "    self.l2 = nn.Linear(nh,n_out)\n",
        "    \n",
        "  def __setattr__(self,k,v):\n",
        "    if not k.startswith(\"_\"): self._modules[k] = v\n",
        "    super().__setattr__(k,v)\n",
        "      \n",
        "  def __repr__(self): return f'{self._modules}'\n",
        "  \n",
        "  def parameters(self):\n",
        "    for l in self._modules.values():\n",
        "      for p in l.parameters(): yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESLJ546MKjn_",
        "colab_type": "code",
        "outputId": "8fa603f9-78ef-462a-d2a0-4d298326899a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "mdl = DummyModule(m,nh,10)\n",
        "mdl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBWVfdopKu5E",
        "colab_type": "code",
        "outputId": "a37b5eb9-b893-4857-aaa9-adeb85403df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFbxhrdjK3Jb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Registering modules\n",
        "\n",
        "We can use the original layers approach, but we have to register the modules.\n",
        "\n",
        "Jump_to lesson 9 video\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN_4P6LLK5Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvtgPE7LBGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i,l in enumerate(self.layers): self.add_module(f'layer_{i}',l)\n",
        "      \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V32URTTLpib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMmFS2-LtB7",
        "colab_type": "code",
        "outputId": "287bff60-922e-4128-b924-a5d4e5857d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hwGcP7hLwwJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "nn.ModuleList\n",
        "\n",
        "nn.ModuleList does this for us.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywzitID4LzKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skd8v5qZMHHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJHITBoiMLsg",
        "colab_type": "code",
        "outputId": "226a4cf2-03fd-4ed9-8fcf-1de6f015f162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF_-4Bj2MPvF",
        "colab_type": "code",
        "outputId": "af11595f-3d28-44eb-d3e6-e4e207df76eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0325, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8x1vmlMazK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "nn.Sequential\n",
        "\n",
        "nn.Sequential is a convenient class which does the same as the above:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vgB3KX7Mcqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u4XIYOqMoMT",
        "colab_type": "code",
        "outputId": "d6ee87a9-6e79-4c4a-966d-784d079fac92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1950, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ieg9gymZM1zY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbCSb_RiM4E5",
        "colab_type": "code",
        "outputId": "8917f8e0-5f12-4056-918d-c940ce0470be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4L7zwj7M7k_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "optim\n",
        "\n",
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "\n",
        "and instead use just:\n",
        "\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJVbQR4TM9vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "  def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params: p -= p.grad * lr\n",
        "        \n",
        "  def zero_grad(self):\n",
        "    for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uwjA6TdUqJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr18ezgmU6WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8SZrcXVVApO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwI5AvCYTZN",
        "colab_type": "code",
        "outputId": "c4a3cf4e-0526-492b-e404-438a07a0a8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1220, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha8Z_7ROYqsr",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWVtdkw2YsuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi6pIX4rYxeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0liDeLjY0uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "  return model, optim.SGD(model.parameters(),lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhC_GCVmZPeU",
        "colab_type": "code",
        "outputId": "447f3234-0b21-4b72-e0f2-0b2cfbbb9cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model.opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1220, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh8iFBOHZnGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K0SVT3uaCX9",
        "colab_type": "code",
        "outputId": "58b53d0a-a5fe-4049-90e7-b0dc77cb32eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0974, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXyOY6BnaS-l",
        "colab_type": "text"
      },
      "source": [
        "Randomized tests can be very useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hf9rOyeaRLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHJwbuwjaa77",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Dataset and DataLoader\n",
        "Dataset\n",
        "\n",
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "\n",
        "xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "\n",
        "Instead, let's do these two steps together, by introducing a Dataset class:\n",
        "\n",
        "xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohSrAZDQadLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Dataset():\n",
        "  def __init__(self, x, y): self.x,self.y = x,y\n",
        "  def __len__(self): return len(self.x)\n",
        "  def __getitem__(self, i): return self.x[i], self.y[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgG_A1Ea7Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid,y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvqYqs4BSLjl",
        "colab_type": "code",
        "outputId": "2b5f4040-bd66-4c1a-aba4-b9415a30e555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhgwWgcdbaRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnW9Zm37bdnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nomp-_BGb8IX",
        "colab_type": "code",
        "outputId": "d2a1b01f-0e3f-487c-e959-3f06d8dc4310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1365, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9RX5f7icK9r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "DataLoader\n",
        "\n",
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "for xb,yb in train_dl:\n",
        "    ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqr0OIZ9cNe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cLXiAKsdOAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TpOmctYdVZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Emg6E0d5xG",
        "colab_type": "code",
        "outputId": "e10cb3e1-f007-43f2-b24f-70aadbb3f680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gXTgu5weBE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb18GR0yeEKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for xb,yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMBWbRN4eYNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2_A3NDXeZiX",
        "colab_type": "code",
        "outputId": "8763d032-cb3a-4b82-d932-3ec3303e9790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1393, grad_fn=<NllLossBackward>), tensor(0.9844))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiaIHsqsewug",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Random sampling\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDvhKt8yezNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "  def __init__(self, ds, bs, shuffle=False):\n",
        "    self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "    \n",
        "  def __iter__(self):\n",
        "    self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "    for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_pRsByMfwxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwhxloLAf5Cx",
        "colab_type": "code",
        "outputId": "29cc2ae7-ab44-4643-adee-d92ac81e6e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzB5N028gRbP",
        "colab_type": "code",
        "outputId": "26b08df4-e0d9-41ca-cac1-cbda2bb783c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([3, 8, 7]), tensor([1, 0, 4]), tensor([2, 9, 6]), tensor([5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30kS39zggiMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "  xs,ys = zip(*b)\n",
        "  return torch.stack(xs),torch.stack(ys)\n",
        "\n",
        "class DataLoader():\n",
        "  def __init__(self, ds, sampler, collate_fn=collate):\n",
        "    self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKBUZ7x1hT1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35XcQ5zPhjaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQy_h-CUhyRJ",
        "colab_type": "code",
        "outputId": "73f85d14-b096-447f-95e0-f455adff80c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzIiTu7wh9mD",
        "colab_type": "code",
        "outputId": "6f2ce1da-f81e-4b2c-af36-30d5edf1840f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbrrxVsuiKqW",
        "colab_type": "code",
        "outputId": "51350f90-48cf-447e-bf07-d0ceac1a107b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9pWWugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UsqiYgxiUUn",
        "colab_type": "code",
        "outputId": "c1163ef8-a4d1-4493-865f-8e293aa1625d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model.opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2168, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeGmdBiIileV",
        "colab_type": "text"
      },
      "source": [
        "PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM621uJFioFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G85ohhHTZzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2B1N-sT8GH",
        "colab_type": "code",
        "outputId": "aff7cd2e-7ca6-49b8-e264-c2bfa5b417fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1841, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB0q9WMIUHf9",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ztK-NFUJey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n2A-jUAUdLe",
        "colab_type": "code",
        "outputId": "bb18be69-fe74-42cc-f3ec-a6c0285c8b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2109, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOd8e8-TVBa-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Note that PyTorch's DataLoader, if you pass num_workers, will use multiple threads to call your Dataset.\n",
        "\n",
        "Validation\n",
        "\n",
        "You always should also have a validation set, in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnB4E_3VVDq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "#         print(model.training)\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                tot_loss += loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Zg__RxVOjc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Question: Are these validation results correct if batch size varies?\n",
        "\n",
        "get_dls returns dataloaders for the training and validation sets:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-iYRD2lVQh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OAS2eqZVVNK",
        "colab_type": "text"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK4KnMdHVTMV",
        "colab_type": "code",
        "outputId": "d93d89c4-5cf0-4d5a-b407-6c783ecfdb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.8504) tensor(0.8080)\n",
            "1 tensor(0.2185) tensor(0.9318)\n",
            "2 tensor(0.2199) tensor(0.9271)\n",
            "3 tensor(0.1023) tensor(0.9700)\n",
            "4 tensor(0.0947) tensor(0.9751)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j44TCkNVcjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgZl6NdKVgFJ",
        "colab_type": "code",
        "outputId": "47d862ad-8c8d-4e76-d972-e8f52d96ec5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!python notebook2script.py 03_minibatch_training.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 03_minibatch_training.ipynb to exp/nb_03.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}